{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d3c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d1719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAN算法,树增强型贝叶斯算法（Tree Augmented Naive Bayes）\n",
    "class Tan(NBayes):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Tan, self).__init__()\n",
    "        self.CMI_dict = dict()                      #条件互信息字典\n",
    "        self.f_relationship = dict()                #特征依赖关系{子特征：父特征（依赖属性）}\n",
    "   \n",
    "    # 计算分类任务的条件互信息\n",
    "    def __CMI_classfic(self, xi, xj, y):\n",
    "        yset = np.unique(y)\n",
    "        y_count = y.size\n",
    "        cmi = 0\n",
    "        for yi in yset:\n",
    "            yi_idx = np.nonzero(np.array(y==yi))[0]\n",
    "            yi_count = yi_idx.size\n",
    "            yi_proba = yi_count/y_count\n",
    "            arr0 = xi[yi_idx]\n",
    "            arr1 = xj[yi_idx]\n",
    "            mi = self.__calDiscreteMutualInformation(arr0, arr1)\n",
    "            cmi += mi * yi_proba\n",
    "        return cmi\n",
    "            \n",
    "    # 计算两个离散特征的互信息\n",
    "    def __calDiscreteMutualInformation(self, arr0, arr1):\n",
    "        # sklearn中现成的\n",
    "        #from sklearn import metrics\n",
    "        #metrics.mutual_info_score(arr0, arr1)\n",
    "        # 自己写的\n",
    "        mi = 0\n",
    "        if len(arr0) != len(arr1):\n",
    "            raise ValueError(\"arr0's length should be qeual to arr1's length!\")\n",
    "        else:\n",
    "            n_samples = len(arr0)\n",
    "            # 数组一的分布统计\n",
    "            setX0 = np.unique(arr0)\n",
    "            bincountX0 = {}\n",
    "            for xi in setX0:\n",
    "                bincountX0[xi] = sum(arr0 == xi)\n",
    "            # 数组二的分布统计\n",
    "            setX1 = np.unique(arr1)\n",
    "            bincountX1 = {}\n",
    "            for xj in setX1:\n",
    "                bincountX1[xj] = sum(arr1 == xj)\n",
    "            # 数组一和数组二的联合分布统计\n",
    "            for i in setX0:\n",
    "                px0 = bincountX0[i]/n_samples\n",
    "                for j in setX1:\n",
    "                    px1 = bincountX1[j]/n_samples\n",
    "                    px0x1 = sum(np.equal(arr0, i)&np.equal(arr1, j))/n_samples\n",
    "                    if px0x1 == 0:\n",
    "                        continue\n",
    "                    mi += px0x1*np.log(px0x1/(px0*px1))\n",
    "        return mi\n",
    "    \n",
    "    # 计算特征之间的条件互信息，并生成字典，目前只生成离散特征之间的依赖关系\n",
    "    def get_cmidict(self, X, y, columnsMark):\n",
    "        n_samples, n_features = X.shape\n",
    "        CMI_dict = dict()\n",
    "        featureIdx = np.nonzero(np.array(columnsMark)==0)[0]\n",
    "        for idx, i in enumerate(featureIdx[:-1]):\n",
    "            for j in featureIdx[idx+1:]:\n",
    "                CMI_dict[(i, j)] = self.__CMI_classfic(X.iloc[:,i], X.iloc[:,j], y)\n",
    "        return CMI_dict\n",
    "    \n",
    "    # 获取特征的依赖关系\n",
    "    def get_relationship(self, features:list, weight:list):\n",
    "        # 获取最大次数的顶点\n",
    "        point_count = dict()\n",
    "        for p0, p1 in features:\n",
    "            if p0 not in point_count.keys():\n",
    "                point_count[p0] = 1\n",
    "            else:\n",
    "                point_count[p0] += 1\n",
    "            if p1 not in point_count.keys():\n",
    "                point_count[p1] = 1\n",
    "            else:\n",
    "                point_count[p1] += 1\n",
    "        pointcntList = sorted(point_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        maxcntFeature = pointcntList[0][0]\n",
    "        # 遍历特征，保存依赖关系\n",
    "        feature_relationship = dict()\n",
    "        feature_epoch = [maxcntFeature]\n",
    "        features_index = []\n",
    "        while len(features_index) < len(features):\n",
    "            for idx, feature_pair in enumerate(features):\n",
    "                if idx in features_index:\n",
    "                    continue\n",
    "                if feature_pair[0] in feature_epoch:\n",
    "                    feature_relationship[feature_pair[1]] = feature_pair[0]\n",
    "                    feature_epoch.append(feature_pair[1])\n",
    "                    features_index.append(idx)\n",
    "                elif feature_pair[1] in feature_epoch:\n",
    "                    feature_relationship[feature_pair[0]] = feature_pair[1]\n",
    "                    feature_epoch.append(feature_pair[0])\n",
    "                    features_index.append(idx)\n",
    "                else:\n",
    "                    feature_relationship[feature_pair[1]] = feature_pair[0]\n",
    "                    feature_epoch.append(feature_pair[1])\n",
    "                    features_index.append(idx)\n",
    "        return feature_relationship\n",
    "    \n",
    "    # TAN算法训练\n",
    "    def TanTrain(self, X, y, columnsMark):\n",
    "        # 1 根据最大带权生成树找到每个特征的依赖属性，目前只在离散变量之间做了父属性\n",
    "        ## 1.1 计算互信息字典\n",
    "        self.CMI_dict = self.get_cmidict(X, y, columnsMark)\n",
    "        \n",
    "        ## 1.2 生成最大带权树\n",
    "        points = list(set([i[0] for i in self.CMI_dict.keys()]+[i[1] for i in self.CMI_dict.keys()]))\n",
    "        self.MaxstClass = MST('max', 'Kruskal')\n",
    "        self.Maxspanningtree = self.MaxstClass.fit_transform(points, self.CMI_dict)\n",
    "        \n",
    "        ## 1.3自定义顶点，使之有向，构建出依赖关系\n",
    "        self.f_relationship = self.get_relationship([f for f, w in self.Maxspanningtree], [w for f, w in self.Maxspanningtree])\n",
    "        \n",
    "        # 2 训练贝叶斯的联合概率、条件概率\n",
    "        ## 2.1 初始化变量，样本数量、特征数量、标签类别、\n",
    "        ##     类别的先验联合概率、联合概率的的条件概率\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        #计算类别的先验概率\n",
    "        self.calPy(y)\n",
    "        print('P(y)训练完毕!')\n",
    "        #yset = np.unique(y)\n",
    "        #Pypa = {}\n",
    "        Pxypa = {}\n",
    "        # 第一层是不同的分类\n",
    "        for yi, yiCount in self.ySet.items():\n",
    "            Pxypa[yi] = {}\n",
    "            # 第二层是不同的特征，如果有父属性，就接着加一层父属性，如果没有父属性，则按实际情况来\n",
    "            for xiIdx in range(self.n_features):\n",
    "                allXiset = np.unique(X.iloc[:, xiIdx])\n",
    "                # 没有父属性的\n",
    "                if xiIdx not in self.f_relationship.keys():\n",
    "                    Xiarr = X.iloc[np.nonzero(np.array(y==yi))[0], xiIdx] # .flatten()\n",
    "                    if columnsMark[xiIdx] == 0:\n",
    "                        ## 保存离散特征的条件概率\n",
    "                        Pxypa[yi][xiIdx] = self.__categorytrain(Xiarr, allXiset)\n",
    "                    else:\n",
    "                        ## 保存连续特征的条件概率\n",
    "                        Pxypa[yi][xiIdx] = self.__continuoustrain(Xiarr)\n",
    "                    continue\n",
    "                \n",
    "                # 第三层是有父属性的，值为父属性的各类值\n",
    "                Pxypa[yi][xiIdx] = {}\n",
    "                paIdx = self.f_relationship[xiIdx]\n",
    "                paset = np.unique(X.iloc[:, paIdx])\n",
    "                for pai in paset:\n",
    "                    xi_pai_idx = np.nonzero(np.array((X.iloc[:,paIdx]==pai)&(y==yi)))[0]\n",
    "                    Xiarr = X.iloc[xi_pai_idx, xiIdx]  #.flatten()\n",
    "                    if columnsMark[xiIdx] == 0:\n",
    "                        ## 保存离散特征的条件概率\n",
    "                        Pxypa[yi][xiIdx][pai] = self.__categorytrain(Xiarr, allXiset)\n",
    "                    else:\n",
    "                        ## 保存连续特征的条件概率\n",
    "                        Pxypa[yi][xiIdx][pai] = self.__continuoustrain(Xiarr)\n",
    "        print('P(x|y,pa)训练完毕!')\n",
    "        self.xyProba = Pxypa\n",
    "        self.trainSet = X\n",
    "        self.trainLabel = y\n",
    "        self.columnsMark = columnsMark        \n",
    "        return \n",
    "\n",
    "    # 计算离散特征的条件概率\n",
    "    def __categorytrain(self, Xarr, xiset):\n",
    "        pxypa = {}\n",
    "        for xivalue in xiset:\n",
    "            pxypa[xivalue] = {}\n",
    "            pxypa[xivalue]['count'] = sum(Xarr==xivalue) + self.ls\n",
    "            pxypa[xivalue]['ratio'] = self.classifyProba(xivalue, Xarr, len(xiset))\n",
    "        return pxypa\n",
    "    \n",
    "    # 计算连续特征的均值和标准差\n",
    "    def __continuoustrain(self, Xarr):\n",
    "        pxypa = (Xarr.mean(), Xarr.std())\n",
    "        return pxypa\n",
    "        \n",
    "    # 预测\n",
    "    def tanpredict(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        proba = np.zeros((n_samples, len(self.yProba)))\n",
    "        for i in range(n_samples):\n",
    "            for idx, (yi, Xidict) in enumerate(self.xyProba.items()):\n",
    "                probaValue = 1.\n",
    "                probaValue *= self.yProba[yi]\n",
    "                for xiIdx, valuedict in Xidict.items():\n",
    "                    xi = X.iloc[i, xiIdx]\n",
    "                    ## 值不是字典，说明是连续变量\n",
    "                    if not isinstance(valuedict, dict):\n",
    "                        miu = valuedict[0]; sigma = valuedict[1] + 1.0e-5\n",
    "                        Pxypa = np.exp(-(xi-miu)**2/(2*sigma**2))/(np.power(2*np.pi, 0.5)*sigma) + 1.0e-5\n",
    "                    ## 第三层不是字典，说明特征没有依赖属性\n",
    "                    elif not isinstance(list(list(valuedict.values())[0].values())[0], dict):\n",
    "                        Pxypa = valuedict[xi]['ratio']\n",
    "                    ## 第三层是字典，说明有依赖属性\n",
    "                    else:\n",
    "                        pai = X.iloc[i, self.f_relationship[xiIdx]]\n",
    "                        Pxypa = valuedict[pai][xi]['ratio']\n",
    "                    probaValue *= Pxypa\n",
    "                proba[i, idx] = probaValue\n",
    "        return proba\n",
    "    \n",
    "    \n",
    "    # 取对数预测\n",
    "    def tanpredictLog(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        proba_log = np.zeros((n_samples, len(self.yProba)))\n",
    "        for i in range(n_samples):\n",
    "            for idx, (yi, Xidict) in enumerate(self.xyProba.items()):\n",
    "                probaValueLog = 0.\n",
    "                probaValueLog += np.log(self.yProba[yi])\n",
    "                for xiIdx, valuedict in Xidict.items():\n",
    "                    xi = X.iloc[i, xiIdx]\n",
    "                    ## 值不是字典，说明是连续变量\n",
    "                    if not isinstance(valuedict, dict):\n",
    "                        miu = valuedict[0]; sigma = valuedict[1] + 1.0e-5\n",
    "                        Pxypa = np.exp(-(xi-miu)**2/(2*sigma**2))/(np.power(2*np.pi, 0.5)*sigma) + 1.0e-5\n",
    "                    ## 第三层不是字典，说明特征没有依赖属性\n",
    "                    elif not isinstance(list(list(valuedict.values())[0].values())[0], dict):\n",
    "                        Pxypa = valuedict[xi]['ratio']\n",
    "                    ## 第三层是字典，说明有依赖属性\n",
    "                    else:\n",
    "                        pai = X.iloc[i, self.f_relationship[xiIdx]]\n",
    "                        Pxypa = valuedict[pai][xi]['ratio']\n",
    "                    probaValueLog += np.log(Pxypa)\n",
    "                proba_log[i, idx] = probaValueLog\n",
    "        return proba_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfff729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (最小/最大)带权生成树相关的算法类(minimun/maxinum spanning tree)\n",
    "class MST(object):\n",
    "    \n",
    "    def __init__(self, tree, method):\n",
    "        \"\"\"\n",
    "        初始化带权生成树，可选择树类型、求解方法等参数\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tree : str\n",
    "            树的类型，包括max, min选择.\n",
    "        method : str\n",
    "            求解方法，包括prim,kruskal算法.\n",
    "\n",
    "        \"\"\"\n",
    "        self.tree = tree.lower()\n",
    "        self.method = method.lower()\n",
    "        self.__reverse_flag = False if self.tree=='min' else True\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 主体训练函数\n",
    "    def fit_transform(self, points:list, edge:dict):\n",
    "        if self.method == 'kruskal':\n",
    "            edge_effective = self.__fit_kruskal(points, edge)\n",
    "        else:\n",
    "            pass\n",
    "        return edge_effective\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 克鲁斯卡尔算法(Kruskal算法)，从边出发\n",
    "    def __fit_kruskal(self, points:list, edge:dict):\n",
    "        # 点的下标，用来判断是否形成环路\n",
    "        pointsmark = np.zeros(len(points))\n",
    "        # 需要保留的边\n",
    "        edgeLeft = []\n",
    "        # 将边正序或者倒序排列\n",
    "        edgeList = sorted(edge.items(), key=lambda x: x[1], reverse=self.__reverse_flag)\n",
    "        # 判断是否形成环路：当边的两个点下标都为1时，则形成了环路\n",
    "        for eg in edgeList:\n",
    "            (p1, p2), w = eg\n",
    "            if (pointsmark[points.index(p1)] == 1) and (pointsmark[points.index(p2)] == 1):\n",
    "                continue\n",
    "            else:\n",
    "                pointsmark[points.index(p1)] = 1\n",
    "                pointsmark[points.index(p2)] = 1\n",
    "                edgeLeft.append(eg)        \n",
    "        return edgeLeft\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d78a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
